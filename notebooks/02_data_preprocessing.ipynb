{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09af12dc",
   "metadata": {},
   "source": [
    "## Data Preprocessing - Food Delivery Time Dataset\n",
    "### Introduction\n",
    "This notebook transforms the raw dataset into machine learning-ready format. We handle missing values, encode categorical variables, and scale numerical features for optimal model performance.\n",
    "\n",
    "**Author:** NGUYEN Ngoc Dang Nguyen - Final-year Student in Computer Science, Aix-Marseille University\n",
    "\n",
    "**Preprocessing Steps:**\n",
    "1. Import Libraries and Load Data\n",
    "2. Missing Values Handling\n",
    "3. Encode Categorical Features\n",
    "4. Feature Scaling\n",
    "5. Train-Test Split\n",
    "6. Save Processed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e79aa0",
   "metadata": {},
   "source": [
    "### 1. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "effabddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 1000 rows and 9 columns\n",
      "Memory usage: 280.2 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order_ID</th>\n",
       "      <th>Distance_km</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Traffic_Level</th>\n",
       "      <th>Time_of_Day</th>\n",
       "      <th>Vehicle_Type</th>\n",
       "      <th>Preparation_Time_min</th>\n",
       "      <th>Courier_Experience_yrs</th>\n",
       "      <th>Delivery_Time_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>522</td>\n",
       "      <td>7.93</td>\n",
       "      <td>Windy</td>\n",
       "      <td>Low</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Scooter</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>738</td>\n",
       "      <td>16.42</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Bike</td>\n",
       "      <td>20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>741</td>\n",
       "      <td>9.52</td>\n",
       "      <td>Foggy</td>\n",
       "      <td>Low</td>\n",
       "      <td>Night</td>\n",
       "      <td>Scooter</td>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>661</td>\n",
       "      <td>7.44</td>\n",
       "      <td>Rainy</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Scooter</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>412</td>\n",
       "      <td>19.03</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Low</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Bike</td>\n",
       "      <td>16</td>\n",
       "      <td>5.0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order_ID  Distance_km Weather Traffic_Level Time_of_Day Vehicle_Type  \\\n",
       "0       522         7.93   Windy           Low   Afternoon      Scooter   \n",
       "1       738        16.42   Clear        Medium     Evening         Bike   \n",
       "2       741         9.52   Foggy           Low       Night      Scooter   \n",
       "3       661         7.44   Rainy        Medium   Afternoon      Scooter   \n",
       "4       412        19.03   Clear           Low     Morning         Bike   \n",
       "\n",
       "   Preparation_Time_min  Courier_Experience_yrs  Delivery_Time_min  \n",
       "0                    12                     1.0                 43  \n",
       "1                    20                     2.0                 84  \n",
       "2                    28                     1.0                 59  \n",
       "3                     5                     1.0                 37  \n",
       "4                    16                     5.0                 68  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"../data/raw/Food_Delivery_Times.csv\")\n",
    "df.columns = df.columns.str.strip() \n",
    "\n",
    "print(f\"Dataset loaded: {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024:.1f} KB\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226af164",
   "metadata": {},
   "source": [
    "### 2. Missing Values Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a86c5d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "Weather                   30\n",
      "Traffic_Level             30\n",
      "Time_of_Day               30\n",
      "Courier_Experience_yrs    30\n",
      "dtype: int64\n",
      "\n",
      "Handling missing values...\n",
      "After handling:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "missing = df.isnull().sum()\n",
    "print(\"Missing values:\")\n",
    "print(missing[missing > 0])\n",
    "\n",
    "print(\"\\nHandling missing values...\")\n",
    "df['Weather'].fillna(df['Weather'].mode()[0], inplace=True)\n",
    "df['Traffic_Level'].fillna(df['Traffic_Level'].mode()[0], inplace=True)  \n",
    "df['Time_of_Day'].fillna(df['Time_of_Day'].mode()[0], inplace=True)\n",
    "df['Courier_Experience_yrs'].fillna(df['Courier_Experience_yrs'].median(), inplace=True)\n",
    "\n",
    "print(\"After handling:\")\n",
    "print(df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2332e2",
   "metadata": {},
   "source": [
    "### 3. Encode Categorical Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4d5583d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before encoding: 9 columns\n",
      "After encoding: 20 columns\n",
      "Weather: 5 new columns : ['Weather_Clear', 'Weather_Foggy', 'Weather_Rainy', 'Weather_Snowy', 'Weather_Windy']\n",
      "Traffic_Level: 3 new columns : ['Traffic_Level_High', 'Traffic_Level_Low', 'Traffic_Level_Medium']\n",
      "Time_of_Day: 4 new columns : ['Time_of_Day_Afternoon', 'Time_of_Day_Evening', 'Time_of_Day_Morning', 'Time_of_Day_Night']\n",
      "Vehicle_Type: 3 new columns : ['Vehicle_Type_Bike', 'Vehicle_Type_Car', 'Vehicle_Type_Scooter']\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = ['Weather', 'Traffic_Level', 'Time_of_Day', 'Vehicle_Type']\n",
    "print(f\"Before encoding: {df.shape[1]} columns\")\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=False)\n",
    "print(f\"After encoding: {df_encoded.shape[1]} columns\")\n",
    "\n",
    "for col in categorical_cols:\n",
    "    new_cols = [c for c in df_encoded.columns if c.startswith(col + \"_\")]\n",
    "    print(f\"{col}: {len(new_cols)} new columns : {new_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f911808",
   "metadata": {},
   "source": [
    "### 4. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db6eae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features scaled\n",
      "        Distance_km  Preparation_Time_min  Courier_Experience_yrs\n",
      "count  1.000000e+03          1.000000e+03            1.000000e+03\n",
      "mean   3.019807e-17          8.526513e-17            9.947598e-17\n",
      "std    1.000500e+00          1.000500e+00            1.000500e+00\n",
      "min   -1.663205e+00         -1.663947e+00           -1.600132e+00\n",
      "25%   -8.702386e-01         -8.307238e-01           -9.032107e-01\n",
      "50%    2.283710e-02          2.499670e-03            1.421721e-01\n",
      "75%    8.706882e-01          8.357231e-01            8.390939e-01\n",
      "max    1.744006e+00          1.668947e+00            1.536016e+00\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = ['Distance_km', 'Preparation_Time_min', 'Courier_Experience_yrs']\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_scaled = df_encoded.copy()\n",
    "df_scaled[numeric_cols] = scaler.fit_transform(df_encoded[numeric_cols])\n",
    "\n",
    "print(\"Numeric features scaled\")\n",
    "print(df_scaled[numeric_cols].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83150466",
   "metadata": {},
   "source": [
    "### 5. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e15080b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (800, 18)\n",
      "Test set: (200, 18)\n",
      "Features: 18\n"
     ]
    }
   ],
   "source": [
    "X = df_scaled.drop(['Order_ID', 'Delivery_Time_min'], axis=1)\n",
    "y = df_scaled['Delivery_Time_min']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"Features: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4305cec0",
   "metadata": {},
   "source": [
    "### 6. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37adc703",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.to_csv(\"../data/processed/processed_data.csv\", index=False)\n",
    "pd.DataFrame(X_train).to_csv(\"../data/processed/X_train.csv\", index=False)\n",
    "pd.DataFrame(X_test).to_csv(\"../data/processed/X_test.csv\", index=False)\n",
    "pd.DataFrame(y_train).to_csv(\"../data/processed/y_train.csv\", index=False)\n",
    "pd.DataFrame(y_test).to_csv(\"../data/processed/y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbe4095",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Preprocessing completed on 1000 records. Missing values (30 total) filled using mode/median. One-hot encoding expanded features to 20 columns. StandardScaler applied to numerical features. Final 80/20 train-test split maintains data integrity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
